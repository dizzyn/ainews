"""
Agent pro generov√°n√≠ personalizovan√©ho p≈ôehledu zpr√°v.

Agent proch√°z√≠ datab√°zi ƒçl√°nk≈Ø, analyzuje jejich d≈Øle≈æitost podle profilu u≈æivatele
a zpravodajsk√Ωch hodnot, a vytv√°≈ô√≠ struƒçn√Ω p≈ôehled nejd≈Øle≈æitƒõj≈°√≠ch ud√°lost√≠.
"""

import os
import json
from typing import List, Dict, Tuple
from datetime import datetime
from dotenv import load_dotenv
from sqlalchemy.orm import Session
from langchain_google_genai import ChatGoogleGenerativeAI
from pydantic import BaseModel, Field

from .database import SessionLocal, engine
from .models import Article, Base

# Naƒçteme .env
load_dotenv()

# Profil u≈æivatele
USER_PROFILE = """
U≈æivatel je ƒçech, ≈æije v Praze.
Zaj√≠m√° ho politika, technologie, ekonomie a ve≈ôejn√© dƒõn√≠.
R√°d by mƒõl p≈ôehled o tom, co h√Ωbe spoleƒçnost√≠.
"""

# Zpravodajsk√© hodnoty (podle https://cs.wikipedia.org/wiki/Zpravodajsk%C3%A9_hodnoty)
NEWS_VALUES = """
Zpravodajsk√© hodnoty:
1. Aktualita - ƒçerstvost ud√°losti
2. Bl√≠zkost - geografick√° nebo kulturn√≠ bl√≠zkost
3. Dopad - poƒçet lid√≠, kter√© ud√°lost ovliv≈àuje
4. Prominentnost - zapojen√≠ zn√°m√Ωch osobnost√≠
5. Konflikt - spory, konflikty, kontroverze
6. Neobvyklost - p≈ôekvapiv√©, neoƒçek√°van√© ud√°losti
7. Lidsk√Ω z√°jem - emocion√°ln√≠ p≈ô√≠bƒõhy
8. Relevance - d≈Øle≈æitost pro spoleƒçnost
"""


class ArticleRelevance(BaseModel):
    """Model pro hodnocen√≠ relevance ƒçl√°nku."""
    article_id: int = Field(description="ID ƒçl√°nku")
    relevance: str = Field(description="Kategorie: Nezaj√≠mav√©, M√°lo zaj√≠mav√©, Velmi zaj√≠mav√©, Nezbytn√©")
    news_value_score: int = Field(description="ƒå√≠seln√© sk√≥re zpravodajsk√© hodnoty 1-10")
    news_values: List[str] = Field(description="Seznam p≈ô√≠tomn√Ωch zpravodajsk√Ωch hodnot")
    reasoning: str = Field(description="Struƒçn√© zd≈Øvodnƒõn√≠ hodnocen√≠")
    country: str = Field(description="Hlavn√≠ zemƒõ zpr√°vy (nap≈ô. ƒåesko, Rusko, USA)")
    person: str = Field(description="Hlavn√≠ osoba zpr√°vy (pokud existuje, jinak pr√°zdn√Ω ≈ôetƒõzec)")
    topic: str = Field(description="Hlavn√≠ t√©ma (politika, ekonomika, technologie, kultura, bezpeƒçnost)")


class ArticleRelevanceList(BaseModel):
    """Seznam hodnocen√≠ ƒçl√°nk≈Ø."""
    articles: List[ArticleRelevance]


class NewsDigestAgent:
    """Agent pro generov√°n√≠ personalizovan√©ho p≈ôehledu zpr√°v."""
    
    def __init__(self):
        """Inicializace agenta."""
        self.llm = ChatGoogleGenerativeAI(
            model=os.getenv("GEMINI_MODEL", "gemini-2.0-flash-lite"),
            google_api_key=os.getenv("GOOGLE_API_KEY"),
            temperature=0.3
        )
        self.db: Session = SessionLocal()
        self.log("Agent inicializov√°n")
    
    def log(self, message: str, verbose: bool = False):
        """V√Ωpis do konzole s ƒçasovou znaƒçkou."""
        if verbose:
            timestamp = datetime.now().strftime("%H:%M:%S")
            print(f"[{timestamp}] {message}")
        else:
            print(message)
    
    def close(self):
        """Uzav≈ôen√≠ datab√°zov√©ho spojen√≠."""
        self.db.close()
    
    def fetch_articles_with_summaries(self) -> List[Article]:
        """Naƒçte v≈°echny ƒçl√°nky se souhrny z datab√°ze."""
        articles = self.db.query(Article).filter(
            Article.summary_simple.isnot(None)
        ).all()
        self.log(f"üì∞ Naƒçteno {len(articles)} ƒçl√°nk≈Ø")
        return articles

    
    def categorize_articles(self, articles: List[Article]) -> List[ArticleRelevance]:
        """
        Kategorizuje ƒçl√°nky podle profilu u≈æivatele a zpravodajsk√Ωch hodnot.
        
        Args:
            articles: Seznam ƒçl√°nk≈Ø k hodnocen√≠
            
        Returns:
            Seznam hodnocen√≠ relevance ƒçl√°nk≈Ø
        """
        self.log(f"üîç Kategorizuji {len(articles)} ƒçl√°nk≈Ø...")
        
        # P≈ôiprav√≠me data pro LLM - pouze souhrny
        articles_data = []
        for article in articles:
            articles_data.append({
                "id": article.id,
                "title": article.title,
                "summary": article.summary_simple,
                "published_date": article.published_date.isoformat() if article.published_date else None
            })
        
        # Zpracov√°n√≠ po d√°vk√°ch (kv≈Øli limitu kontextu)
        batch_size = 20
        all_relevances = []
        
        for i in range(0, len(articles_data), batch_size):
            batch = articles_data[i:i + batch_size]
            
            prompt = f"""You are an expert in news analysis. Your task is to evaluate the relevance of articles according to user profile and news values.

{USER_PROFILE}

{NEWS_VALUES}

For each article determine:
1. Relevance category: Nezaj√≠mav√©, M√°lo zaj√≠mav√©, Velmi zaj√≠mav√©, Nezbytn√©
2. News value score: 1-10 (overall importance score)
3. Which news values are present
4. Main country (e.g., ƒåesko, Rusko, USA, Nƒõmecko)
5. Main person (if any, otherwise empty string)
6. Main topic (politika, ekonomika, technologie, kultura, bezpeƒçnost)
7. Brief reasoning in Czech

Respond in JSON array format with objects:
{{
  "article_id": <id>,
  "relevance": "<kategorie>",
  "news_value_score": <1-10>,
  "news_values": ["hodnota1", "hodnota2"],
  "country": "<zemƒõ>",
  "person": "<osoba nebo pr√°zdn√Ω ≈ôetƒõzec>",
  "topic": "<t√©ma>",
  "reasoning": "<zd≈Øvodnƒõn√≠ v ƒçe≈°tinƒõ>"
}}

Articles to evaluate:
{json.dumps(batch, ensure_ascii=False, indent=2)}

Respond only with JSON array, no additional text."""
            
            response = self.llm.invoke(prompt)
            
            # Parsov√°n√≠ JSON odpovƒõdi
            try:
                response_text = response.content.strip()
                # Odstranƒõn√≠ markdown code blocku pokud existuje
                if response_text.startswith("```"):
                    response_text = response_text.split("```")[1]
                    if response_text.startswith("json"):
                        response_text = response_text[4:]
                    response_text = response_text.strip()
                
                batch_results = json.loads(response_text)
                for item in batch_results:
                    all_relevances.append(ArticleRelevance(
                        article_id=item["article_id"],
                        relevance=item["relevance"],
                        news_value_score=item.get("news_value_score", 5),
                        news_values=item["news_values"],
                        country=item.get("country", ""),
                        person=item.get("person", ""),
                        topic=item.get("topic", ""),
                        reasoning=item["reasoning"]
                    ))
            except Exception as e:
                self.log(f"‚ùå Chyba p≈ôi parsov√°n√≠: {e}")
                continue
        
        self.log(f"‚úÖ Kategorizov√°no {len(all_relevances)} ƒçl√°nk≈Ø")
        return all_relevances
    
    def select_articles_for_digest(self, relevances: List[ArticleRelevance], articles: List[Article]) -> Tuple[List[ArticleRelevance], Dict]:
        """
        Vybere a se≈ôad√≠ ƒçl√°nky pro fin√°ln√≠ p≈ôehled.
        
        Args:
            relevances: Seznam hodnocen√≠ ƒçl√°nk≈Ø
            articles: Seznam ƒçl√°nk≈Ø z datab√°ze
            
        Returns:
            Tuple (se≈ôazen√© relevance, mapa ƒçl√°nk≈Ø podle ID)
        """
        # Prioritizace: Nezbytn√© > Velmi zaj√≠mav√© > M√°lo zaj√≠mav√©
        priority_map = {
            "Nezbytn√©": 4,
            "Velmi zaj√≠mav√©": 3,
            "M√°lo zaj√≠mav√©": 2,
            "Nezaj√≠mav√©": 1
        }
        
        # Vybereme top ƒçl√°nky (minim√°lnƒõ Velmi zaj√≠mav√©)
        selected_relevances = [
            rel for rel in relevances 
            if rel.relevance in ["Nezbytn√©", "Velmi zaj√≠mav√©"]
        ][:15]
        
        # Pokud je m√°lo ƒçl√°nk≈Ø, p≈ôid√°me i "M√°lo zaj√≠mav√©"
        if len(selected_relevances) < 5:
            more = [rel for rel in relevances if rel.relevance == "M√°lo zaj√≠mav√©"][:10]
            selected_relevances.extend(more)
        
        # Se≈ôad√≠me podle news_value_score
        selected_relevances.sort(key=lambda x: x.news_value_score, reverse=True)
        
        # Vytvo≈ô√≠me mapu ƒçl√°nk≈Ø
        articles_map = {a.id: a for a in articles}
        
        # V√Ωpis se≈ôazen√Ωch zpr√°v
        self.log(f"\nüìä Se≈ôazen√© zpr√°vy podle hodnoty:")
        for rel in selected_relevances:
            article = articles_map.get(rel.article_id)
            if article:
                title_short = article.title[:60] + "..." if len(article.title) > 60 else article.title
                self.log(f"  [{rel.news_value_score}/10] {rel.relevance[:4]}. | {rel.country:8} | {title_short}")
        
        self.log(f"\n‚úÖ Vybr√°no {len(selected_relevances)} ƒçl√°nk≈Ø\n")
        return selected_relevances, articles_map
    
    def generate_digest(self, selected_relevances: List[ArticleRelevance], articles_map: Dict) -> str:
        """
        Vygeneruje fin√°ln√≠ p≈ôehled zpr√°v z vybran√Ωch ƒçl√°nk≈Ø.
        
        Args:
            selected_relevances: Se≈ôazen√© hodnocen√≠ ƒçl√°nk≈Ø
            articles_map: Mapa ƒçl√°nk≈Ø podle ID
            
        Returns:
            Textov√Ω p≈ôehled zpr√°v
        """
        self.log(f"‚úçÔ∏è  Generuji p≈ôehled...")
        
        # P≈ôiprav√≠me data pro LLM s metadaty pro lep≈°√≠ spojov√°n√≠
        articles_content = []
        for rel in selected_relevances:
            article = articles_map.get(rel.article_id)
            if article:
                articles_content.append({
                    "title": article.title,
                    "summary": article.summary_simple,
                    "country": rel.country,
                    "person": rel.person,
                    "topic": rel.topic,
                    "score": rel.news_value_score
                })
        
        # Prompt pro generov√°n√≠ p≈ôehledu
        prompt = f"""Jsi zku≈°en√Ω novin√°≈ô. Tv√Ωm √∫kolem je napsat struƒçn√Ω p≈ôehled nejd≈Øle≈æitƒõj≈°√≠ch zpr√°v.

{USER_PROFILE}

KRITICK√Å PRAVIDLA SPOJOV√ÅN√ç:
Priority pro spojov√°n√≠ zpr√°v do jedn√© vƒõty:
1. NEJVY≈†≈†√ç: T√Ωkaj√≠ se stejn√© osoby (person)
2. VYSOK√Å: T√Ωkaj√≠ se stejn√© zemƒõ (kromƒõ "ƒåesko" - ƒçesk√© zpr√°vy nespojuj)
3. ST≈òEDN√ç: Maj√≠ podobn√Ω nebo opaƒçn√Ω dopad
4. N√çZK√Å: Jsou ze stejn√©ho t√©matu (topic)

STRUKTURA:
- D√©lka: 6-8 vƒõt (max 600 znak≈Ø)
- Zaƒçni hodnot√≠c√≠m koment√°≈ôem, pak vyjmenuj zpr√°vy jako argumenty
- P≈ô√≠klad: "Rusko pokraƒçuje v represi - perzekuce intelektu√°l≈Ø se stup≈àuje a ƒåerven√Ω k≈ô√≠≈æ spolupracuje s Kremlem."
- ≈òaƒè zpr√°vy podle score (nejvy≈°≈°√≠ prvn√≠)

STYL:
- Krat≈°√≠ fr√°ze: "stalo se" m√≠sto "do≈°lo k", "v" m√≠sto "v oblasti"
- Plynul√Ω text, ne seznam
- T√≥n: rychl√Ω, v√Ωsti≈æn√Ω, ƒçtiv√Ω

ƒål√°nky k zpracov√°n√≠ (se≈ôazen√© podle d≈Øle≈æitosti):
{json.dumps(articles_content, ensure_ascii=False, indent=2)}

Napi≈° p≈ôehled v ƒçe≈°tinƒõ:"""
        
        response = self.llm.invoke(prompt)
        digest_text = response.content
        
        self.log(f"‚úÖ P≈ôehled vygenerov√°n ({len(digest_text)} znak≈Ø)")
        return digest_text

    
    def save_digest(self, digest_text: str):
        """
        Ulo≈æ√≠ p≈ôehled do datab√°ze (p≈ôep√≠≈°e p≈ôedchoz√≠).
        
        Args:
            digest_text: Text p≈ôehledu k ulo≈æen√≠
        """
        # Vytvo≈ô√≠me nebo aktualizujeme z√°znam
        # Pou≈æijeme speci√°ln√≠ ƒçl√°nek s ID=0 nebo URL="DIGEST"
        digest_article = self.db.query(Article).filter(Article.url == "DIGEST").first()
        
        if digest_article:
            # Aktualizujeme existuj√≠c√≠
            digest_article.title = f"P≈ôehled zpr√°v - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
            digest_article.content = digest_text
            digest_article.summary_simple = digest_text
            digest_article.published_date = datetime.now()
        else:
            # Vytvo≈ô√≠me nov√Ω
            digest_article = Article(
                url="DIGEST",
                title=f"P≈ôehled zpr√°v - {datetime.now().strftime('%Y-%m-%d %H:%M')}",
                content=digest_text,
                summary_simple=digest_text,
                published_date=datetime.now()
            )
            self.db.add(digest_article)
        
        self.db.commit()
        self.log(f"üíæ Ulo≈æeno do DB")
    
    def run(self):
        """Hlavn√≠ loop agenta - spust√≠ cel√Ω proces generov√°n√≠ p≈ôehledu."""
        try:
            self.log("üöÄ START: Generov√°n√≠ p≈ôehledu zpr√°v")
            
            # 1. Naƒçteme ƒçl√°nky se souhrny
            articles = self.fetch_articles_with_summaries()
            
            if not articles:
                self.log("‚ö†Ô∏è  ≈Ω√°dn√© ƒçl√°nky k zpracov√°n√≠")
                return
            
            # 2. Kategorizujeme ƒçl√°nky
            relevances = self.categorize_articles(articles)
            
            # 3. Vybereme a se≈ôad√≠me ƒçl√°nky pro p≈ôehled
            selected_relevances, articles_map = self.select_articles_for_digest(relevances, articles)
            
            if not selected_relevances:
                self.log("‚ö†Ô∏è  ≈Ω√°dn√© relevantn√≠ ƒçl√°nky")
                return
            
            # 4. Vygenerujeme p≈ôehled
            digest = self.generate_digest(selected_relevances, articles_map)
            
            # 5. Ulo≈æ√≠me do datab√°ze
            self.save_digest(digest)
            
            self.log(f"\n{'='*60}")
            self.log(f"üì∞ V√ùSLEDN√ù P≈òEHLED:")
            self.log(f"{'='*60}")
            self.log(digest)
            self.log(f"{'='*60}\n")
            self.log("‚úÖ HOTOVO")
            
        except Exception as e:
            self.log(f"‚ùå CHYBA: {str(e)}")
            raise
        finally:
            self.close()


def main():
    """Hlavn√≠ funkce pro spu≈°tƒõn√≠ agenta."""
    agent = NewsDigestAgent()
    agent.run()


if __name__ == "__main__":
    main()
